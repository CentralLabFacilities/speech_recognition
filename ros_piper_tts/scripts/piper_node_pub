#!/usr/bin/env python3
import rospy
import actionlib
import numpy as np

from clf_speech_msgs.msg import ASR
from clf_speech_msgs.msg import TTSAction, TTSGoal, TTSResult, TTSFeedback
from clf_speech_msgs.srv import Translate, TranslateRequest
import audio_common_msgs.msg as audio_msgs
from std_srvs.srv import Trigger

from ros_piper_tts import piper_tts
import clf_audio_util.utils as util

from unidecode import unidecode

def chunker(seq, size):
    return (seq[pos:pos + size] for pos in range(0, len(seq), size))


class PiperNode(object):
    # create messages that are used to publish feedback/result
    _feedback = TTSFeedback()
    _result = TTSResult()

    def __init__(self, model_dir, default_speaker, translate):
        self.model_dir = model_dir

        self.voices = {}

        self.configure()

        v = self.get_voice(default_speaker)
        if v is None:
            rospy.logerr(f"default_speaker not found: {default_speaker}")
        else:
            self.voices["default"] = v
            # This is just to warmup the default network
            data = self.voices["default"].synthesize("Good Morning")
            for d in data:
                pass

        self._as = actionlib.SimpleActionServer(
            "/piper_tts",
            TTSAction,
            execute_cb=self.execute_cb,
            auto_start=False,
        )

        rospy.loginfo(">>> Starting ue sound publisher")
        self._pub = rospy.Publisher(
            "/ue_audio/audio",
            audio_msgs.AudioData,
            queue_size=10
        )

        self.translate = translate
        if translate:
            self._translate_client = rospy.ServiceProxy("/translate", Translate)
            rospy.loginfo("waiting for /translate connection...")
            self._translate_client.wait_for_service()

        self._as.start()
        rospy.loginfo("piper_tts started")

    def configure(self):
        meta_param = rospy.get_param("/piper_tts/models", [])
        print(meta_param)

        param_names = rospy.get_param_names()
        self.model_names = []
        for param_name in param_names:
            # If the parameter is like '/piper_tts/models/NAME/voice'
            if "/piper_tts/models" in param_name and "/voice" in param_name:
                motion_name = param_name.replace("/piper_tts/models/", "")
                motion_name = motion_name.replace("/voice", "")
                self.model_names.append(motion_name)

        for model in self.model_names:
            param = rospy.get_param(f"/piper_tts/models/{model}")
            voice = param["voice"]

            rospy.loginfo(f"Loading /piper_tts/models/{model} with {voice}")
            try:
                onnx, config = piper_tts.get_model(self.model_dir, voice)
                self.voices[model] = piper_tts.PiperTTS(onnx, config)
            except rospy.ROSException as e:
                rospy.logwarn(f"could not load '{model}', ignored")

    def get_voice(self, langid):
        if langid == "":
            langid = "default"

        if langid in self.voices.keys():
            return self.voices[langid]
        else:
            rospy.logerr(f"failed to find voice {langid}")
            return None

    def execute_cb(self, goal: TTSGoal):
        r = rospy.Rate(10)
        success = True

        rospy.loginfo(f"got request {goal}")

        text_to_speak = goal.text
        if goal.text_lang != goal.speaker_lang:
            if not self.translate:
                rospy.logwarn("translation disabled and text_lang!=speaker_lang")
                # self._as.set_aborted()
                # return
            else:
                s = util.lang_to_flores200.get(goal.text_lang, "unknown")
                t = util.lang_to_flores200.get(goal.speaker_lang, None)
                if t is None:
                    rospy.logerr(
                        f"unknown translation language, translator may default to EN"
                    )

                translate = TranslateRequest()
                translate.text = goal.text
                translate.target_lang = goal.speaker_lang
                res = self._translate_client.call(translate)
                rospy.loginfo(
                    f"translated [{s}]->[{t}]: '{text_to_speak}' -> '{res.text}'"
                )
                text_to_speak = res.text

        self._result.text = text_to_speak

        speaker = goal.speakerName
        if speaker == "":
            # Default to speaker_lang
            speaker = util.lang_from_int(goal.speaker_lang)
            voice = self.get_voice(speaker)
            if voice is None:
                speaker = ""
                voice = self.get_voice(speaker)
                # unidecode to make sure we can speak this?
                text_to_speak = unidecode(text_to_speak)
                self._result.text = text_to_speak

        else:
            self.get_voice(goal.speakerName)

        if voice is None:
            rospy.logerr(f"speaker '{speaker}' not found")
            self._as.set_aborted()
            return

        rospy.loginfo(f"say({speaker}): {text_to_speak}")
        audio_stream = voice.synthesize(text_to_speak)

        # Each "data" object is one sentence ended by '.'
        for data in audio_stream:

            npa = data.audio_int16_array.astype(np.float32)
            npa = npa / 32768.0
            npa = npa.tobytes()
            
            # 65500 is max size for messages using DDS with UDP (see fastdds config)
            for chunk in chunker(list(npa), 65500):

                audio_data = audio_msgs.AudioData()
                audio_data.data = chunk

                self._pub.publish(audio_data)

            # Using service for triggering playback in UE because action server implementation in rclUE doesn't support goal
            # status properly. Ugly as hell but it works for now.
            playback_finished = False
            rospy.wait_for_service('/ue_audio/trigger_playback')
            while not playback_finished:
                try:
                    trigger_playback = rospy.ServiceProxy('/ue_audio/trigger_playback', Trigger)
                    resp = trigger_playback()
                    playback_finished = resp.success
                    rospy.loginfo(f"Triggered UE audio playback: {resp.success}, {resp.message}")
                except rospy.ServiceException as e:
                    rospy.logerr(f"Service call failed: {e}")
                    success = False
                    break

                if self._as.is_preempt_requested():
                    self._as.set_preempted()
                    success = False
                    return
                
                rospy.sleep(0.5)

        rospy.loginfo(f"playback done {success}")

        if success:
            self._as.set_succeeded(self._result)
        else:
            self._as.set_aborted()


if __name__ == "__main__":

    # Start ROS node
    rospy.init_node("piper_tts")
    translate = rospy.get_param("~translate", False)
    model_dir = rospy.get_param("~model_dir", "/home/robocup/Projects/MA/ros_one_ws/src/speech_recognition/ros_piper_tts/models")
    default_model = rospy.get_param("~default_model", "en")
    PiperNode(model_dir, default_model, translate)
    rospy.spin()
